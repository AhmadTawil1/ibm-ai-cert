{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f711a2aa-da50-4295-bee3-f03ee077ae4a",
   "metadata": {},
   "source": [
    "# üìä Multiple Linear Regression\n",
    "\n",
    "---\n",
    "\n",
    "## üîπ What Is Multiple Linear Regression?\n",
    "\n",
    "**Multiple Linear Regression (MLR)** is an extension of **Simple Linear Regression** that uses **two or more independent variables** (features) to estimate a **continuous dependent variable** (target). It models a linear relationship between inputs and outputs.\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Regression Equation\n",
    "\n",
    "Given a dataset with multiple features:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n\n",
    "$$\n",
    "\n",
    "- \\( \\hat{y} \\): Predicted value  \n",
    "- \\( \\theta_0 \\): Intercept (bias term)  \n",
    "- \\( \\theta_1, \\theta_2, \\ldots, \\theta_n \\): Coefficients for each feature  \n",
    "- \\( x_1, x_2, \\ldots, x_n \\): Feature values\n",
    "\n",
    "This equation defines:\n",
    "- A **line** in 2D (simple regression)\n",
    "- A **plane** in 3D\n",
    "- A **hyperplane** in higher dimensions\n",
    "\n",
    "---\n",
    "\n",
    "## üß† How MLR Works\n",
    "\n",
    "1. Inputs are organized into a matrix **X**, including a column of ones to account for the bias term \\( \\theta_0 \\).\n",
    "2. Coefficients \\( \\theta \\) are estimated using techniques such as:\n",
    "   - **Ordinary Least Squares (OLS)** (via closed-form solution with matrix algebra)\n",
    "   - **Gradient Descent** (an optimization-based approach)\n",
    "\n",
    "---\n",
    "\n",
    "## üßÆ Example Calculation\n",
    "\n",
    "Suppose we have:\n",
    "\n",
    "- \\( \\theta_0 = 125 \\), \\( \\theta_1 = 6.2 \\), \\( \\theta_2 = 14 \\)  \n",
    "- A car with:  \n",
    "  - Engine size = 2.4  \n",
    "  - Cylinders = 4  \n",
    "\n",
    "Then:\n",
    "\n",
    "$$\n",
    "\\hat{y} = 125 + 6.2 \\cdot 2.4 + 14 \\cdot 4 = 214.1\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## üìâ Model Evaluation\n",
    "\n",
    "Residual error for one record:\n",
    "\n",
    "$$\n",
    "\\text{Residual}_i = y_i - \\hat{y}_i\n",
    "$$\n",
    "\n",
    "Average squared residuals:\n",
    "\n",
    "$$\n",
    "\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "Objective: **Minimize the MSE** to find the best-fit parameters.\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Advanced: Optimization with Gradient Descent\n",
    "\n",
    "- Start with random coefficients\n",
    "- Iteratively minimize error using the gradient of the loss function\n",
    "- Useful for large datasets where matrix inversion (used in OLS) is expensive\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öñÔ∏è Simple vs. Multiple Linear Regression\n",
    "\n",
    "| Aspect                | Simple Linear Regression | Multiple Linear Regression |\n",
    "|-----------------------|--------------------------|-----------------------------|\n",
    "| # of Features         | 1                        | 2 or more                   |\n",
    "| Output                | Line                     | Plane or hyperplane         |\n",
    "| Interpretability      | Very simple              | More complex                |\n",
    "| Flexibility           | Limited                  | Higher modeling power       |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Pitfalls of Multiple Linear Regression\n",
    "\n",
    "- **Overfitting**: Too many features can make the model memorize instead of generalize.\n",
    "- **Collinearity**: Features that are strongly correlated introduce instability in coefficient estimation.\n",
    "- **Impossible Scenarios in What-If Analysis**: Changing one variable independently may not make sense if it's correlated with others.\n",
    "- **Outliers**: Strongly affect model accuracy and coefficient estimates.\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Variable Selection Tips\n",
    "\n",
    "To build a good MLR model:\n",
    "- Avoid redundant (correlated) variables\n",
    "- Use features that are **understood**, **controllable**, and **strongly correlated** with the target\n",
    "- Encode categorical variables:\n",
    "  - **Binary**: 0 = Manual, 1 = Automatic\n",
    "  - **Multi-class**: Use one-hot encoding (Boolean flags)\n",
    "\n",
    "---\n",
    "\n",
    "## üì¶ Real-World Applications\n",
    "\n",
    "| Domain         | Example Use |\n",
    "|----------------|-------------|\n",
    "| **Education**  | Predict exam scores using time spent studying, attendance, anxiety levels, etc. |\n",
    "| **Healthcare** | Estimate changes in blood pressure from BMI, age, and lifestyle |\n",
    "| **Environment**| Predict CO‚ÇÇ emissions using engine size, cylinders, and fuel consumption |\n",
    "| **Finance**    | Forecast revenue using multiple economic indicators |\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "- **MLR** is a powerful, interpretable method for predicting a continuous variable using multiple inputs.\n",
    "- It's flexible but must be used with care to avoid **overfitting** and **collinearity issues**.\n",
    "- Common estimation methods: **Ordinary Least Squares** and **Gradient Descent**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d7094-c735-4a32-b0c6-3d1acc76179b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
